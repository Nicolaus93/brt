from collections import defaultdict
from itertools import combinations
from utils import *
from tqdm import tqdm


class Node(object):
    """
    Parameters:
        - Ti, the label of the cluster?
        - pi, is the prior prob that all the data
            in the node is kept in one cluster
            instead of being partitioned into sub-trees
    """

    def __init__(self, data, common_concepts, likelihood=1):
        assert type(common_concepts) == set

        self.Dm = data
        self.Cm = common_concepts
        self.children = []
        self.likelihood = likelihood
        self.label = self.Dm[0]

    def __repr__(self):
        if len(self.children) > 0:
            return str(self.label)
        else:
            return str(self.Dm[0])

    def name(self):
        return self.__repr__()


class bayes_rose_tree(object):
    """
    Bayesian Rose Tree.
    Input:
        - entities, dict
        - concepts, dict
        - gamma_0, float - hyperparameter
        - pi, float - hyperparameter between 0 and 1
    """

    def __init__(self, entities, concepts, gamma_0=0.2, pi=0.5):

        self.c_prior = prior(concepts)
        self.n_clusters = len(entities)
        self.pi = pi

        self.e_tipicality = defaultdict(dict)
        for concept in concepts:
            # p(e|c)
            self.e_tipicality[concept] = tipicality(concepts, concept)

        self.nodes = set()
        self.concepts = defaultdict(set)
        for entity in entities:
            common_concepts = set(entities[entity].keys())
            new_node = Node([entity], common_concepts)
            for concept in common_concepts:
                self.concepts[concept].add(new_node)
            self.nodes.add(new_node)

    def __repr__(self):
        ret = ''
        for node in self.nodes:
            # ret += node.__repr__()
            if len(node.children) == 0:
                print(node, end=', ')
            else:
                print("\n")
                print_tree(node)
        return ret

    def node_likelihood(self, node):
        """
        Returns p(Dm|Tm).
        Input:
            - node, Node object
        """
        if len(node.children) == 0:
            # leaf node
            return 1

        prior = tot_ps(node.Cm, self.c_prior)
        first_term = self.pi * marginal(
            node.Dm, node.Cm, prior, self.e_tipicality)

        second_term = (1 - self.pi)
        for child in node.children:
            second_term *= child.likelihood
        return first_term + second_term

    def join(self, Ti, Tj):
        """
        Join 2 nodes Ti and Tj.
        Input:
            - Ti, Tj, Node objects
        Returns:
            - Tm likelihood, float
            - Tm, new Node object
        """
        common_concepts = Ti.Cm & Tj.Cm
        if len(common_concepts) == 0:
            # there is no common concept for Dm,
            # the words in Dm cannot be generated by
            # a single model
            return None, 0

        data = Ti.Dm + Tj.Dm
        Tm = Node(data, common_concepts)
        Tm.children.extend([Ti, Tj])
        Tm.likelihood = self.node_likelihood(Tm)
        return Tm, Tm.likelihood

    def absorb(self, Ti, Tj):
        """
        Absorb 1 node.
        Input:
            - Ti (Node), absorbing node
            - Tj (Node), absorbed node
        """
        if len(Ti.children) == 0:
            # The node selected should have at least 1 child
            return None, 0

        data = Ti.Dm + Tj.Dm
        common_concepts = Ti.Cm & Tj.Cm
        if len(common_concepts) == 0:
            return None, 0

        Tm = Node(data, common_concepts)
        Tm.children.append(Tj)
        Tm.children += Ti.children
        Tm.likelihood = self.node_likelihood(Tm)
        return Tm, Tm.likelihood

    def collapse(self, Ti, Tj):
        """
        Collapse 2 nodes.
        """
        if len(Ti.children) or len(Tj.children) == 0:
            return None, 0

        data = Ti.Dm + Tj.Dm
        common_concepts = Ti.Cm & Tj.Cm
        if len(common_concepts) == 0:
            return None, 0

        Tm = Node(data, common_concepts)
        Tm.children += Ti.children + Tj.children
        Tm.likelihood = self.node_likelihood(Tm)
        return Tm, Tm.likelihood

    def algo(self, k=100, verbose=False):
        """
        Algorithm revised.
        """
        for i in tqdm(range(k)):

            node, pair, op, score = self.select_pair()

            if node is None:
                print("Interrupted")
                break

            self.select_label(node)
            for concept in node.Cm:
                self.concepts[concept].add(node)
            self.nodes.add(node)

            Ti, Tj = pair[0], pair[1]
            self.remove(Ti)
            self.remove(Tj)

            if verbose:
                print("{}: {}, {} remaining nodes".format(
                    op, score, len(self.nodes)))
                print(self)
                print("\n")

        return

    def select_pair(self):
        """
        Fine the pair of trees Ti and Tj and the merge operation
        that can maximize the likelihood ratio:

                            p(Dm | Tm)
                L(Tm) = _____________________
                        p(Di | Ti) p(Dj | Tj)
        """

        best_score = 0
        best_node = None
        best_pair = (None, None)
        op = 'None'
        # for concept in self.concepts:
        #     for pair in combinations(self.concepts[concept], 2):
        for pair in combinations(self.nodes, 2):
            Ti, Tj = pair[0], pair[1]
            if len(Ti.Cm & Tj.Cm) == 0:
                continue
            den = Ti.likelihood * Tj.likelihood
            join_node, join_score = self.join(Ti, Tj)
            absorb_node, absorb_score = self.absorb(Ti, Tj)  # maybe absorb(Tj, Ti)?
            collapse_node, collapse_score = self.collapse(Ti, Tj)
            absorb_node, absorb_score = None, 0
            collapse_node, collapse_score = None, 0

            scores = (join_score, absorb_score, collapse_score)
            maxim = max(scores)

            # if maxim <= .5:
            #     continue

            new_score = maxim / den
            if new_score > best_score:
                if maxim == absorb_score:
                    best_node = absorb_node
                    op = 'absorb'
                elif maxim == join_score:
                    best_node = join_node
                    op = 'join'
                else:
                    best_node = collapse_node
                    op = 'collapse'

                best_score = new_score
                best_pair = (Ti, Tj)
        return best_node, best_pair, op, best_score

    def select_label(self, node):
        """
        Select the label of a new node from its set of
        common concepts.
        """
        best_score = 0
        for concept in node.Cm:
            # now look at eq. 12 in the paper
            concept_score = conditional(
                node.Dm, self.e_tipicality[concept]) * self.c_prior[concept]
            if concept_score > best_score:
                best_score = concept_score
                best_concept = concept
        node.label = best_concept

    def remove(self, node):
        """
        Update all dictionaries once the best pair is found.
        """
        self.nodes.remove(node)
        for concept in node.Cm:
            self.concepts[concept].remove(node)

    def adjust(self):
        for node in self.nodes:
            res = True
            while res:
                res = post_process(node)


def post_process(node):
    if len(node.children) == 0:
        return False
    else:
        for child in node.children:
            if child.label == node.label:
                for grandchild in child.children:
                    node.children.append(grandchild)
                node.children.remove(child)
                return True
            post_process(child)


if __name__ == '__main__':

    """
                          ┌clothing
                     ┌item┤
                     │    └food
             ┌expense┤
             │       │    ┌transportation
             │       └cost┤
             │            └insurance
     industry┤
             │                 ┌chemical
             │        ┌industry┤
             │        │        └energy
             └industry┤
                      │    ┌oil
                      └fuel┤
                           └gas
    """

    concepts = set(['set', 'list'])
    data = ['leaf']
    a = Node(data, concepts)
    b = Node(data, concepts)
    c = Node(data, concepts)
    d = Node(data, concepts)
    e = Node(data, concepts)
    f = Node(data, concepts)
    g = Node(data, concepts)
    a.label = 'industry'
    a.children = [b, c]
    b.label = 'industry'  # or fuel
    b.children = [d, e]
    d.label = 'gas'
    e.label = 'oil'
    c.label = 'industry'
    c.children = [f, g]
    f.label = 'chemical'
    g.label = 'energy'
    print_tree(a)
    res = True
    while res:
        res = post_process(a)
    print_tree(a)
