from collections import defaultdict
from itertools import combinations
from utils import *
from tqdm import tqdm
import random


class Node(object):
    """
    Parameters:
        - Ti, the label of the cluster?
        - pi, is the prior prob that all the data
            in the node is kept in one cluster
            instead of being partitioned into sub-trees
    """

    def __init__(self, data, common_concepts, likelihood=1):
        assert type(common_concepts) == set

        self.Dm = data
        self.Cm = common_concepts
        self.children = []
        self.likelihood = likelihood
        self.label = self.Dm[0]

    def __repr__(self):
        if len(self.children) > 0:
            return str(self.label)
        else:
            return str(self.Dm[0])

    def name(self):
        return self.__repr__()


class bayes_rose_tree(object):
    """
    Bayesian Rose Tree.
    Input:
        - entities, dict
        - concepts, dict
        - gamma_0, float - hyperparameter
        - pi, float - hyperparameter between 0 and 1
    """

    def __init__(self, entities, concepts, gamma_0=0.2, pi=0.5):

        self.c_prior = prior(concepts)
        self.n_clusters = len(entities)
        self.pi = pi

        self.e_tipicality = defaultdict(dict)
        for concept in concepts:
            # p(e|c)
            self.e_tipicality[concept] = tipicality(concepts, concept)

        self.nodes = set()
        self.concepts = defaultdict(set)
        for entity in entities:
            common_concepts = set(entities[entity].keys())
            new_node = Node([entity], common_concepts)
            for concept in common_concepts:
                self.concepts[concept].add(new_node)
            self.nodes.add(new_node)

    def __repr__(self):
        ret = ''
        for node in self.nodes:
            # ret += node.__repr__()
            if len(node.children) == 0:
                print(node, end=', ')
            else:
                print("\n")
                print_tree(node)
        return ret

    def node_likelihood(self, node):
        """
        Returns p(Dm|Tm).
        Input:
            - node, Node object
        """
        if len(node.children) == 0:
            # leaf node
            return 1

        prior = tot_ps(node.Cm, self.c_prior)
        first_term = self.pi * marginal(
            node.Dm, node.Cm, prior, self.e_tipicality)

        second_term = (1 - self.pi)
        for child in node.children:
            second_term *= child.likelihood
        return first_term + second_term

    def join(self, Ti, Tj):
        """
        Join 2 nodes Ti and Tj.
        Input:
            - Ti, Tj, Node objects
        Returns:
            - Tm likelihood, float
            - Tm, new Node object
        """
        common_concepts = Ti.Cm & Tj.Cm
        if len(common_concepts) == 0:
            # there is no common concept for Dm,
            # the words in Dm cannot be generated by
            # a single model
            return None, 0

        data = Ti.Dm + Tj.Dm
        Tm = Node(data, common_concepts)
        Tm.children.extend([Ti, Tj])
        Tm.likelihood = self.node_likelihood(Tm)
        return Tm, Tm.likelihood

    def absorb(self, Ti, Tj):
        """
        Absorb 1 node.
        Input:
            - Ti (Node), absorbing node
            - Tj (Node), absorbed node
        """
        if len(Ti.children) == 0:
            # The node selected should have at least 1 child
            return None, 0

        data = Ti.Dm + Tj.Dm
        common_concepts = Ti.Cm & Tj.Cm
        if len(common_concepts) == 0:
            return None, 0

        Tm = Node(data, common_concepts)
        Tm.children.append(Tj)
        Tm.children += Ti.children
        Tm.likelihood = self.node_likelihood(Tm)
        return Tm, Tm.likelihood

    def collapse(self, Ti, Tj):
        """
        Collapse 2 nodes.
        """
        if len(Ti.children) or len(Tj.children) == 0:
            return None, 0

        data = Ti.Dm + Tj.Dm
        common_concepts = Ti.Cm & Tj.Cm
        if len(common_concepts) == 0:
            return None, 0

        Tm = Node(data, common_concepts)
        Tm.children += Ti.children + Tj.children
        Tm.likelihood = self.node_likelihood(Tm)
        return Tm, Tm.likelihood

    def algo(self, k=100, streaming=False, verbose=False):
        """
        Algorithm revised.
        """
        for i in tqdm(range(k)):

            node, pair, op, score = self.select_pair()

            if node is None:
                print("Interrupted")
                break

            self.select_label(node)
            for concept in node.Cm:
                self.concepts[concept].add(node)
            self.nodes.add(node)

            Ti, Tj = pair[0], pair[1]
            self.remove(Ti)
            self.remove(Tj)

            if verbose:
                print("{}: {}, {} remaining nodes".format(
                    op, score, len(self.nodes)))
                print(self)
                print("\n")

        return

    def select_pair(self):
        """
        Fine the pair of trees Ti and Tj and the merge operation
        that can maximize the likelihood ratio:

                            p(Dm | Tm)
                L(Tm) = _____________________
                        p(Di | Ti) p(Dj | Tj)
        """

        best_score = 0
        best_node = None
        best_pair = (None, None)
        op = 'None'
        # for concept in self.concepts:
        #     for pair in combinations(self.concepts[concept], 2):
        for pair in combinations(self.nodes, 2):
            Ti, Tj = pair[0], pair[1]
            if len(Ti.Cm & Tj.Cm) == 0:
                continue
            den = Ti.likelihood * Tj.likelihood
            join_node, join_score = self.join(Ti, Tj)
            # absorb_node, absorb_score = self.absorb(Ti, Tj)  # maybe absorb(Tj, Ti)?
            # collapse_node, collapse_score = self.collapse(Ti, Tj)
            # we actually don't need those
            absorb_node, absorb_score = None, 0
            collapse_node, collapse_score = None, 0

            scores = (join_score, absorb_score, collapse_score)
            maxim = max(scores)

            # if maxim <= .5:
            #     continue

            new_score = maxim / den
            if new_score > best_score:
                if maxim == absorb_score:
                    best_node = absorb_node
                    op = 'absorb'
                elif maxim == join_score:
                    best_node = join_node
                    op = 'join'
                else:
                    best_node = collapse_node
                    op = 'collapse'

                best_score = new_score
                best_pair = (Ti, Tj)
        return best_node, best_pair, op, best_score

    def algo_streaming(self, k=200, gamma=0.5):

        already_seen = set()
        for i in tqdm(range(k)):

            # sample node (simulate streaming)
            try:
                Ti = random.sample(self.nodes, 1)[0]
            except Exception:
                print("no more nodes to stream")
                self.nodes = already_seen
                Ti = random.sample(self.nodes, 1)[0]

            while Ti.children == 0:
                Ti = random.sample(self.nodes, 1)[0]

            # removed sampled node from self.nodes
            self.nodes.remove(Ti)
            node, Tj, score = self.select_pair_streaming(Ti, already_seen)
            if node is None or score <= gamma:
                already_seen.add(Ti)
                continue

            # select label
            self.select_label(node)

            already_seen.add(node)
            already_seen.remove(Tj)

        # return already_seen
        self.nodes = already_seen

    def select_pair_streaming(self, Ti, nodes):
        """
        Right now only performing "join" operation.
        """

        best_score = 0
        best_node = None
        best_buddy = None

        for Tj in nodes:
            if len(Ti.Cm & Tj.Cm) == 0:
                continue
            den = Ti.likelihood * Tj.likelihood
            join_node, join_score = self.join(Ti, Tj)
            if join_score / den > best_score:
                best_node = join_node
                best_score = join_score / den
                best_buddy = Tj
        return best_node, best_buddy, best_score

    def select_label(self, node):
        """
        Select the label of a new node from its set of
        common concepts.
        """
        best_score = 0
        for concept in node.Cm:
            # now look at eq. 12 in the paper
            concept_score = conditional(
                node.Dm, self.e_tipicality[concept]) * self.c_prior[concept]
            if concept_score > best_score:
                best_score = concept_score
                best_concept = concept
        node.label = best_concept

    def remove(self, node):
        """
        Update all dictionaries once the best pair is found.
        """
        self.nodes.remove(node)
        for concept in node.Cm:
            self.concepts[concept].remove(node)

    def adjust(self):
        for node in self.nodes:
            post_process(node)


def post_process(node):
    """
    If we only use join, we need this function to absorb
    and collapse nodes as in the original article.
    """
    if len(node.children) == 0:
        return
    else:
        i = 0
        while True:
            if i >= len(node.children):
                break
            child = node.children[i]
            post_process(child)
            if child.label == node.label:
                node.children.pop(i)
                node.children = child.children + node.children
                i += len(child.children)
            else:
                i += 1


if __name__ == '__main__':

    """
                      ┌energy
             ┌industry┤
             │        └chemical
     industry┤
             │        ┌gas
             └industry┤
                      └oil
    Becomes:

             ┌leaf
             ├leaf
     industry┤
             ├leaf
             └leaf

    """

    concepts = set(['set', 'list'])
    data = ['leaf']
    a = Node(['energy', 'chemical', 'gas', 'oil'], concepts)
    b = Node(['energy', 'chemical'], concepts)
    c = Node(['gas', 'oil'], concepts)
    d = Node(['energy'], concepts)
    e = Node(['industry'], concepts)
    f = Node(['gas'], concepts)
    g = Node(['industry'], concepts)
    h = Node(['chemical'], concepts)
    i = Node(['oil'], concepts)

    e.children = [h]
    g.children = [i]
    a.label = 'industry'
    a.children = [b, c]
    b.label = 'industry'  # or fuel
    b.children = [d, e]
    d.label = 'energy'
    e.label = 'industry'
    c.label = 'industry'
    c.children = [f, g]
    f.label = 'gas'
    g.label = 'industry'
    print_tree(a)
    post_process(a)
    print_tree(a)
